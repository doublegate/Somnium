# Somnium: AI Adventure Game Design Document (Expanded)

## Overview & Vision

Somnium is a **graphical text-adventure game** that fuses the nostalgic aesthetics and technical philosophy of Sierra On-Line’s early SCI-era games (e.g., _King’s Quest IV_, _Space Quest III_) with the power of modern Large Language Models (LLMs). The vision is to create a “new” classic adventure every time the player starts the game. An LLM effectively acts as a real-time **Dungeon Master**, generating a unique plot, world, characters, puzzles, music themes, and dialogue for each playthrough. This promises an experience of pure discovery, replicating the feeling of unwrapping a new Sierra game for the first time. The player should feel as if they’ve unearthed a lost 1989 masterpiece, complete with the era’s signature sights and sounds, yet powered by infinite narrative possibilities.

Each generated adventure is ephemeral and unique—a self-contained narrative universe that will never exist exactly the same way again—yet it can be saved and revisited at any time. By blending a faithful retro presentation with the limitless storytelling of AI, **Somnium offers endless replayability** within a cherished, classic framework that prioritizes puzzle-solving and exploration.

### Core Features

- **AI-Generated Adventures:** Every core element of the game world—from the overarching plot and character motivations down to the specific layout of rooms, item descriptions, and puzzle logic—is generated by an LLM at the start of a new game. No two adventures are ever the same, yet each follows a coherent structure ensuring it is solvable and engaging.

- **SCI0-Style Interface:** The player experience is meticulously modeled on Sierra’s SCI0 engine interface. The game display is a 320×200 pixel graphic scene with a menu bar on top (with classic menus like **File**, **Game**, **Speed**, **Help**). All text interactions – both the player’s input and the game’s descriptive output – occur within a pop-up text window, preserving the authentic screen layout of the late 1980s. The interface supports keyboard input for commands and arrow keys for character movement, similar to titles like _King’s Quest IV_ and _Space Quest III_. Notably, typing a command **pauses the game action**, giving players unlimited time to enter even long commands (an enhancement introduced in SCI0 games like KQ4). The top of the screen displays the game’s title and the player’s score, just as Sierra games showed a running score and game title in the menu bar.

- **EGA-Style Graphics:** We enforce a **strict 16-color EGA palette** and 320×200 resolution to replicate the look of 1988–1989 Sierra adventures. The artistic style captures the rich, “painterly” feel of SCI0 artwork, with detailed use of dithering to simulate additional colors and smooth gradients. Backgrounds are drawn with **vector-style primitives** just like Sierra’s PIC format, which used drawing commands and dithering to produce intricate scenes in minimal memory. Character and object sprites (called “VIEW” resources in Sierra terms) are similarly limited in color and size, with chunkier pixel art that blends into the background. _(See the Graphics Generation Guide for detailed techniques.)_

- **Dynamic Music & Sound:** An AI-driven soundtrack provides a unique score for every adventure, using era-appropriate synthesized music. Musical themes and ambient soundscapes change based on location and in-game events, powered by the Web Audio API (using Tone.js) to recreate the feel of classic MIDI devices like the AdLib and Roland MT-32. Every playthrough might feature different melodies fitting the theme (e.g. spooky minor key for horror, bright fanfare for fantasy), yet all with that retro **polyphonic MIDI** quality. Sound effects are also generated or selected to match the late-80s aesthetic (simple waveforms or FM synthesis). The audio system is **modular** to support multiple sound hardware profiles – akin to how Sierra games supported PC speaker, Tandy 3-voice, AdLib, and MT-32 sound options – but modernized under the hood for web playback.

- **Save/Load Functionality:** Players can save the complete state of a generated world to their local machine as a single file, and reload it later to continue the same adventure. This captures their “dream” and all its unique content indefinitely. (Details in the Save/Load File Format Spec.) Because each world is AI-generated and unique, saving also preserves the original generated data so that the adventure can be perfectly reconstructed even if the AI that created it is not invoked again.

- **Puzzle-Driven Gameplay:** True to Sierra classics, Somnium emphasizes exploration and puzzle solving. The game design encourages the player to talk to characters, gather and use inventory items, solve environmental puzzles, and progress through a narrative that has a clear goal (e.g. _“find the lost treasure and escape the island”_). The puzzles are generated by the AI but follow the logical structures seen in games like _Leisure Suit Larry 2_, _Police Quest 2_, etc. – typically inventory or dialogue puzzles where a certain item or clue is needed to overcome an obstacle. Each puzzle is guaranteed solvable with the clues and items provided in that world’s generation. The Sierra influence means some puzzles might have lighthearted solutions or require paying attention to descriptions for subtle hints, just as those classic games often did.

- **Classic Challenge and Charm:** We take inspiration from Sierra’s design ethos to include optional points scoring (e.g., finding hidden easter eggs or solving puzzles in an optimal way might award points), and even the possibility of failure states. Like in Sierra games, the player character **can die** or get stuck if they make a dire mistake (stepping off a cliff, etc.), but Somnium will always autosave before unwinnable situations and allow multiple save slots. The tone of writing, generated by the LLM, strives to emulate the original games – whether it’s the gentle fairytale narration of _King’s Quest_, the sarcastic humor of _Space Quest_, or the bawdy jokes of _Leisure Suit Larry_ (within moderated limits).

## The SCI Engine Philosophy on the Web

The original Sierra Creative Interpreter (SCI) engine was a landmark virtual machine that separated game content from the engine. Game data was stored in compressed resource files (`*.SCR`, `*.PIC`, `*.VOC`, etc.), and the engine ran this data on a variety of hardware. Somnium adopts this **decoupled philosophy** to ensure authenticity and flexibility. The key idea is that the **engine is story-agnostic**: it doesn’t have hard-coded puzzles or scenes; it only knows how to interpret and present game data. This clean separation allows the AI to generate new content packages that our engine can run without code changes – just like Sierra’s interpreter could run any SCI game script.

- **AI as the Resource Compiler:** In our workflow, the LLM effectively serves as the “compiler” or content creator. Instead of a human developer manually coding a game and drawing art, the LLM generates a single, large JSON object at the start of a new game. This JSON is analogous to a compiled resource package in SCI. It contains everything needed for one complete adventure: background definitions (like Sierra’s PIC drawings), character sprites and animations (like VIEW resources), sound cues (like SOUND resources), room definitions, puzzles, and script logic. The quality and coherence of the gameplay experience hinge on the consistency of this AI-generated package, much like the quality of a Sierra game depended on the content the designers and artists created.

- **JavaScript as the Interpreter:** Our game engine, written in JavaScript, acts as the interpreter or virtual machine that loads and executes the generated JSON package. The engine does not hard-code any story or puzzle; it provides generic capabilities (rendering graphics, playing sounds, moving sprites, parsing input, managing state) and executes whatever content is in the JSON. This mimics the original SCI design where the interpreter was general-purpose, and the game-specific logic was in data files. Thanks to this, our system is **highly modular** and future-proof: the same engine can run any number of AI-generated worlds, and improvements to the engine benefit all past and future worlds. Conversely, the engine can be extended (for example, to support new kinds of interactions or graphics) without needing to change the content generation prompt, because the prompt can be adjusted to produce data in the new format.

- **Era-Authentic Constraints:** Adopting the SCI0 philosophy means embracing constraints that ironically make content generation easier to manage. For example, limiting to 16 colors and low resolution reduces the complexity of artwork the AI must describe. Short textual descriptions and memory limits evoke the brevity of classic game narrations, which keeps the LLM’s output concise. We also enforce the idea of separate resource types (scripts vs. pics vs. sounds), which helps structure the AI’s JSON output clearly into distinct sections, much like the original SCI had separate resource files. These constraints channel the AI’s creativity in productive ways and ensure the final result feels cohesive and authentic to the late-80s adventure style.

- **Sierra’s Influence:** Sierra’s SCI0 games (1988–1989) ran on hardware with **severe limits** (512KB RAM, floppy disks, no true color, etc.). Our engine, while running on vastly more powerful modern hardware, intentionally enforces similar limits in the simulation. This not only keeps the style consistent, but also forces efficiency. For instance, Sierra’s use of vector-drawn backgrounds means our JSON can’t simply embed large image files; instead it must use drawing commands (which the engine will execute to paint the scene). Similarly, any text output from the LLM must be relatively short and to the point (as verbose paragraphs wouldn’t fit in the small on-screen text windows). By following these old-school constraints, we ensure that the AI’s output and the engine’s rendering stay within a realm that feels like a genuine 1989 product.

## Core Gameplay Loop

The gameplay loop is event-driven, mirroring the flow of a classic SCI game interpreter and aiming for a seamless, responsive player experience.

1. **Game Initiation:** The player selects **“New Adventure”** from the menu (or the game might auto-start on load). Optionally, the player may input a **seed keyword or theme** (e.g., “haunted mansion”, “cyberpunk city”, “tropical island”) to guide the AI’s creative process for this world. This choice is fed into the generation prompt to influence the setting and tone.

2. **AI World Generation:** Upon starting a new game, the engine’s AI Manager constructs a _master prompt_ and sends it to the LLM (over an asynchronous API call). This master prompt requests a full game JSON (see **LLM Interaction Protocols** document for details of the prompt and format). While waiting for the LLM’s response, the game shows a **loading screen** styled like a classic Sierra boot-up sequence. For example, it might display a retro Sierra logo or simply some witty “status messages” generated by the AI (e.g., “Calibrating dream matrices... Weaving narrative threads...”) to entertain the player during the brief pause. Once the LLM returns the JSON, the engine parses it to ensure it’s valid and complete.

3. **Game World Initialization:** The engine then loads the JSON into the GameState, effectively “compiling” all the resources. The very first room (the starting room) is rendered immediately: the engine draws its background (PIC) and places any initial visible characters or objects (VIEWs) on screen. If the room’s data specifies background music or ambient sound, the SoundManager begins playing those tracks. The player is now looking at the opening scene of their unique adventure, with the description likely printed in the text window (either automatically or after the first prompt).

4. **Main Loop – Waiting for Player Input:** At this point, the game enters the main event loop. The player can explore and interact by typing commands into the text parser window. The engine remains idle, continuously rendering the scene and running background animations or timed events, until the player enters a command. The user’s command can also be triggered by certain key presses (e.g., arrow keys to move, or function keys for inventory, help, etc.), which the engine interprets as equivalent textual commands (“go north”, “show inventory,” etc.).

5. **Player Input & Parsing:** When the player types a command and presses Enter (e.g., `> LOOK AT DRAGON`), the Parser module processes it. The parser is designed to understand a variety of phrasings and synonyms: e.g. `> EXAMINE THE DRAGON`, `> WHAT IS THE DRAGON` would all resolve to a core action `look_at(dragon)`. It breaks down the input into a structured format, identifying the intended _verb_ (action) and _noun_ (target), and any indirect object (e.g., `USE KEY ON DOOR` has verb=use, direct object=key, indirect object=door). The parser cross-references nouns with the current room’s entities (objects, items, characters present) to find what the player is referring to. If the command or wording is not understood at all, the engine will respond with a generic message (in Sierra tradition, something like “I don’t understand that.” or a more contextual hint), possibly generated via LLM for flavor.

6. **Event Script Execution:** The parsed command is then handed to the EventManager, which is the core of game logic execution. The EventManager checks the game’s data to see if there is a predefined script or event associated with the target object and action. For example, if the player looked at the dragon, it checks the dragon object’s data for an `onLook` script. If the player tries to `USE KEY ON DOOR`, it checks the door or the key object for an `onUse` or similar event that specifically handles using that key on that door (or a more general puzzle script that matches this action). These scripts (defined in the JSON by the LLM) are deterministic and ensure important puzzles have explicit solutions. If a matching scripted event is found, the engine executes the sequence of actions defined in that script. This might include: printing a description or dialogue to the text window, changing some state (flags or object properties), moving the player or an NPC, playing a sound effect, triggering an animation, etc.. For instance, a door’s `onUnlock` script might check a condition (does the player have the correct key and is the key usable?), then play a “door unlocking” sound and open the door (perhaps enabling an exit to a new room).

7. **Dynamic LLM Interaction (for Unscriped Actions):** If the EventManager does **not** find a specific script for the player’s command, this doesn’t mean the action fails. Instead, Somnium leverages the LLM for **emergent interactions**. The engine will formulate a **dynamic prompt** to the LLM, describing the current context (current room description, relevant objects, recent events, etc.) and the player’s attempted action, asking the LLM to respond as the game. This allows the game to handle more open-ended commands intelligently. For example, if the player tries to `TALK TO DRAGON ABOUT WEATHER` and no scripted dialogue exists for that specific topic, the LLM might generate a fun response on the fly (perhaps the dragon snorts and says it prefers stormy weather). These LLM responses are used to make the world feel responsive and alive beyond the “critical path” puzzles. The engine integrates the LLM’s answer by displaying the generated text as if it were a game response. In some cases, the LLM may also suggest a minor state change (for instance, setting a flag that the dragon is now annoyed if you keep bothering it), but our dynamic prompt is carefully designed to avoid contradictions or breaking the game’s logic. Essentially, the LLM serves as a fallback for handling creative player inputs that the original JSON didn’t explicitly cover.

8. **Update State & Rendering:** After an action is executed (whether via a scripted event or a dynamic LLM response), the game state is updated accordingly. This includes inventory changes (e.g., if the player picked up an item, remove it from the room and add to inventory), flag updates (e.g., `dragon_is_angry = true` if we upset the dragon), object visibility or properties (e.g., a door object’s “locked” property might become false), and so on. The SceneRenderer and ViewManager then re-draw the scene as needed to reflect changes. For example, if a door opened, the background might be redrawn with an open door image or a new exit highlight; if the dragon’s expression changed, its sprite (VIEW) might switch to a different animation loop or frame. The engine ensures that any on-screen changes happen smoothly. Animated objects continue their loops, and any new animations triggered (like an NPC walking) are started via the ViewManager.

9. **Looping Back:** With the state updated and the scene rendered, the main loop returns to waiting for the next player command. In the meantime, background tasks continue: character idle animations play, any timed scripts (like “after 2 minutes, the guard enters the room”) will execute via the GameManager’s timers, and music or ambience might change if triggered by time or conditions. The player is free to explore further, look around, and try the next action. This loop repeats until the player either **wins** (triggers the end-game condition defined in the generated story) or decides to quit. If the player’s character dies due to some hazard, the engine will typically present a “Game Over” message (possibly humorously, in Sierra fashion) and offer to restore a save or restart.

10. **Win Condition & Reset:** Each generated game has a clear goal defined in its “plot” (e.g., _find the magical fruit to save the king_, as a win scenario). When the player achieves this goal (solves the final puzzle), the game triggers a win sequence. This may include a special victory message or scene (the LLM might generate an ending description), possibly accompanied by a final score tally (_e.g., “Congratulations! You have scored 210 of 230 points.”_). After the ending, the player can choose to save the final state, return to main menu, or generate a new adventure. Starting a new adventure would repeat the whole generation and initialization process with a fresh world.

Throughout this loop, **user experience** considerations are kept in mind. The game will provide feedback for unknown commands (possibly via LLM as mentioned), and the parser allows abbreviations for common commands (e.g., “look” = “look around”, “inv” = “check inventory”). Also, a menu or keyboard shortcuts allow quick actions: _Game > Inventory_ to list carried items, _Game > Save/Load_ for managing saves, _Help_ menu for a quick reference of commands, and _Speed_ menu to adjust animation/game speed (a common feature in Sierra games to speed up long walks or slow down for difficult action sequences). The entire design aims to **mimic the feel of Sierra’s SCI0 adventures** while leveraging AI to enrich interactions beyond what was possible in 1989.

## Technical Architecture

**Platform:** Somnium runs as a web application (HTML/CSS/JavaScript), requiring no installation beyond a modern web browser. The game logic executes client-side, with asynchronous calls to an LLM service for content generation and dynamic interactions. Graphics are drawn to an HTML5 `<canvas>` element for the game scene. Sound is handled via the Web Audio API (using the Tone.js library for scheduling music and sound effects). The architecture is modular, divided into several core components or managers, each responsible for a facet of the game (graphics, sound, input, AI integration, etc.). This section outlines the key modules of the engine (the “interpreter”):

- **GameManager.js** – _The Core Engine:_ Orchestrates the overall game flow and main loop. It uses `requestAnimationFrame` to drive the rendering and updates, maintaining a consistent frame rate. GameManager handles global state transitions (e.g., pausing the game when the menu is open), the **game speed** setting (throttling or speeding up how fast animations and timers run, as in the classic Speed menu), and a queue of timed events (like delays or scheduled scripts) that need to trigger (e.g., a countdown until an in-game event). It acts as a central hub, initializing other managers and ensuring they work in sync.

- **AIManager.js** – _The AI Integrator:_ Manages all communication with the LLM. It is responsible for constructing the **initial world generation prompt** (using any player-provided seed/themes and the fixed format for JSON output) and sending it to the LLM API. Upon receiving the JSON, AIManager validates and passes it to GameState for loading. During gameplay, AIManager also handles **dynamic prompts** for unscripted interactions: it gathers relevant context (current room description, recent events, inventory, etc.) and queries the LLM for a response to the player’s input when needed. It may also implement safety checks or fallback logic if the LLM returns invalid data. Essentially, AIManager is the bridge between the game engine and the AI service.

- **GameState.js** – _The World’s Memory:_ Holds the entire state of the current game world. This includes static data from the generated JSON (rooms, items, puzzles definitions, object properties) and dynamic data reflecting changes as the player progresses (flags, which puzzles are solved, which items have been picked up, character positions, etc.). GameState provides an API for other modules to query and modify the world state in a structured way. For example, the Parser might ask GameState “is there an object named ‘dragon’ in the current room?” and EventManager might tell GameState “set flag `dragon_is_angry` to true”. By centralizing state, we ensure saving/loading is straightforward (since GameState can be serialized) and consistency is maintained across the game.

- **SceneRenderer.js** – _The Graphics Card:_ Responsible for drawing the static backgrounds (the PIC resources) on the canvas. It interprets the `graphics` part of the room JSON which contains a list of drawing primitives (shapes, colors, coordinates) to recreate the background image by issuing the appropriate canvas drawing commands. This is analogous to Sierra’s vector drawing of backgrounds. SceneRenderer also helps composite the final scene by providing an interface for drawing dynamic objects on top of the background, handling basic z-ordering (depth) rules. For example, it might clear and redraw the background when needed, and it works with ViewManager to place sprites so that if a character is “behind” a tree (based on y-coordinate priority), it draws the character first or uses a mask to achieve the correct layering. It essentially simulates the **visual screen** of SCI, while an internal mechanism can also simulate the priority screen for depth sorting (we can assign each pixel row or an object a priority value akin to Sierra’s priority bands to determine draw order).

- **ViewManager.js** – _The Animator:_ Manages all animated sprites, equivalent to Sierra’s VIEW resources for characters and interactive objects. Each sprite has multiple frames (cels) and might have multiple animation loops (for example, separate loops for “idle”, “walking”, “talking”, etc., similar to how Sierra’s view resource could contain multiple loops like walking in different directions). The ViewManager updates these animations on each tick of the game loop: it advances frames based on timing, and moves sprites if they have a path or motion (for instance, an NPC walking across the room). It tells SceneRenderer where and when to draw each sprite’s current frame. The ViewManager also handles **collision or interaction zones** for sprites if needed, and ensures that characters animate at the correct speed relative to the game speed setting. Pathfinding in Somnium is simple – often just linear movement to a coordinate – but ViewManager could be extended with basic pathfinding if we define obstacles in a room’s data (e.g., if an NPC should walk around a table, we might implement a simple route or use the control map concept).

- **SoundManager.js** – _The Sound Card:_ Handles music and sound playback using Tone.js or HTML5 Audio. At game start, SoundManager reads any global or room-specific sound configuration from the JSON. For each room, it may load or generate a music loop (Tone.js can proceduraly generate music from a given descriptor prompt) and an ambient loop (background sound like wind, chatter, etc.). It also preloads short sound effect clips that might be needed (for example, if the JSON described a “door creak” sound or if puzzles have specific sounds). During gameplay, SoundManager responds to events: if the player triggers a sound action (like a SOUND resource to play), it mixes that sound in. It ensures only appropriate sounds play simultaneously (maybe limiting the number of concurrent effects to avoid cacophony, as old sound chips had limited channels). Importantly, the SoundManager can interpret simple descriptors given by the AI – e.g., if the AI specifies a music theme with certain instruments, SoundManager chooses matching synthetic instrument patches (like “synth_brass” or “flute” presets) to compose the music. All music is played in a style reminiscent of Sierra’s early soundtracks (simple melodies, looping background scores, etc.), respecting the memory that those tunes were often short leitmotifs rather than fully orchestrated pieces.

- **Parser.js** – _The Language Interface:_ Implements the text parser that interprets player input. It contains a vocabulary of understood verbs and synonyms (e.g., “look” = “examine”, “take” = “pick up” = “grab”) and some grammar handling to allow flexible input. The parser’s job is to normalize the raw text input into a structured command: for example, “UNLOCK THE HEAVY DOOR WITH THE BRASS KEY” becomes `{verb: "unlock", directObject: "heavy_door", indirectObject: "brass_key"}`. It uses the GameState to validate the nouns (ensuring “heavy door” exists in the current room, and “brass key” is either in inventory or in the room). If disambiguation is needed (e.g., two keys), it might ask the player for clarification. The parser also supports simple pronouns and memory (like “open it” following a mention of an object). We also incorporate some of Sierra’s parser quirks: not requiring articles (player can type “open door” instead of “open the door”), and understanding simple sentences like “give dwarf beer” as well as “give beer to dwarf”. If the parser fails to understand, it triggers a message or a dynamic LLM query for an “I don’t understand” response that might humorously reflect what the player typed. Overall, the Parser is designed to be forgiving and flexible, to accommodate natural phrasing as much as possible (with the LLM’s help for unusual phrasings).

- **EventManager.js** – _The Script Runner:_ Coordinates execution of in-game events once the Parser identifies what the player wants to do. It first checks the target object or item for a defined event script corresponding to the action (e.g., for object “control_panel”, check if there’s an `onPush` event if the player used the “push” verb). If found, EventManager executes that script’s actions one by one. Actions can include setting game flags, modifying object state (like hiding/showing an object or changing its description after use), enabling or disabling room exits, triggering sounds or animations, awarding points to the player’s score, etc.. Scripts can also contain conditional logic: for example, a script might specify a condition that must be true for an action to succeed (as in the `onPush` example that only works if `power_is_on == true`). If a condition fails and a fallback response is defined (like `onPush_fallback` in the example), it will execute that instead. If no explicit script is defined for the action, EventManager passes the request on to AIManager to handle via LLM (as described in the gameplay loop). Essentially, EventManager is the heart of game logic, ensuring deterministic puzzle solutions work every time and delegating anything unspecified to the AI. It also manages any **timed events** (in conjunction with GameManager) – for example, a script might schedule a function to run after a delay (like a bomb ticking down, or an NPC entering later) which EventManager will queue and execute at the right time.

In addition to these core modules, there are supporting components such as **Menu/UI handlers** (to manage the top menu clicks, open the Save/Load dialogs, etc.), **InputManager** (to capture keyboard input and send it to Parser or to handle special keys), and **InventoryManager** (to display and manage the player’s inventory, if not handled entirely by GameState and EventManager logic).

The **web technology stack** is straightforward: all game rendering happens in a single-page web app. We use standard JavaScript (ES6+), and we ensure compatibility with major browsers. Because everything runs client-side except the LLM calls, the game can function offline _after_ generation (you need internet to generate content or handle unscripted queries, but if you play within a pre-generated world without asking novel questions beyond scripts, it can run offline).

The engine is optimized to handle typical game sizes akin to Sierra titles: on the order of 20–50 rooms, 20–40 items, 5–10 major puzzles, and a handful of characters. Modern hardware can certainly handle more, but we limit scope to ensure the AI output remains coherent and to keep within a reasonable memory footprint (also making save files small). The architecture does not assume heavy GPU usage; the canvas rendering is simple enough for integrated graphics, and Tone.js can generate music with minimal CPU. We avoid using large frameworks to keep things lightweight – just vanilla JS and a few small libraries (for audio or perhaps for structured storage).

## AI-Generated "Resource" System

The master JSON generated by the LLM contains the entire game content structured into various resource sections, closely mimicking the resource types of an SCI game for familiarity and organization. The primary sections and their roles are:

- **Plot:** High-level story info, including:

  - `title`: A creative title for the adventure.
  - `backstory`: A brief introduction or premise that sets the stage (e.g., “You are a detective stranded in a mysterious mansion…”).
  - `goal`: A one-sentence summary of the ultimate objective for the player (e.g., “Find the lost crown and reclaim your throne.”).

  This section gives context to tie everything together and can be shown in an “About Game” or on the title screen. It’s analogous to the game’s documentation or opening narrative that Sierra games often included.

- **Rooms:** An array of room objects, each representing one location/screen in the game:

  - `id`: Unique identifier (used for linking exits, etc.), e.g., `"dwarf_cave"`.
  - `name`: Short display name, e.g., `"Dwarven Cave"`, shown in save files or debug.
  - `description`: Text description shown when the player enters or looks around the room. This sets the scene, written in second person present tense (typical Sierra narration style).
  - `exits`: A mapping of directions (north, south, east, west, up, down, etc.) to target room IDs, for navigation. For example, `"north": "forest_path"` if going north leads to the forest path room.
  - `items`: A list of item IDs present in the room initially (these refer to entries in the global items list). This populates the room with things the player can pick up or examine.
  - `objects`: A list of interactive object IDs present in the room. These refer to entries in a global “objects” list (the JSON format expects the AI to include interactive scenery or NPCs here).
  - `sound`: An object describing the room’s audio environment:

    - `music_theme`: A prompt or descriptor for background music in this room (e.g., `"A slow, echoing, mysterious theme using synth pads and a single flute-like lead."`).
    - `ambience`: A description of ambient loop sound (e.g., `"The low hum of machinery and occasional crackle of static."`).

  - `graphics`: An object defining the background picture of the room:

    - `backgroundColor`: A hex code for the base background fill (one of the 16 EGA colors, e.g., `"#0000AA"` for blue).
    - `primitives`: An array of drawing commands to create the scene. Each primitive can be:

      - A basic shape like `rect` (rectangle) or `polygon` with a color.
      - A special pattern like `dithered_gradient` to blend two EGA colors.
      - Possibly custom shapes like `circle`, `line`, or domain-specific ones (`star` as used in examples).
      - Each primitive may have attributes: `dims` (dimensions or coordinates), `points` (for polygon vertices or multiple points), and a `label` (optional identifier for reference, e.g., labeling a region like “floor” or “table”).

    - The primitives are ordered in the list as the drawing order (from background to foreground).

  This detailed room structure allows the engine to reconstruct both the textual and visual aspect of each location.

- **Items:** An array of item objects (things that can be picked up or carried by the player):

  - `id`: Unique ID (lowercase, e.g., `"brass_key"`).
  - `name`: The text name shown to the player (“a brass key”).
  - `description`: The text that appears when the player _looks at_ or examines the item, either in the room or in their inventory.
  - (Optional other fields: perhaps `initialRoom` if not using the `rooms[].items` lists, but in our format the presence in a room’s item list is enough. Also, possibly a `use` description if used generically, but puzzle logic usually covers usage.)

  Items defined here are global and can be in rooms or inventory. By listing them separately, we ensure consistency (the item has the same description everywhere) and allow cross-references (puzzles refer to item IDs).

- **Puzzles:** An array of puzzle definitions, each representing a challenge or obstacle the player must overcome:

  - `id`: Unique ID for the puzzle (e.g., `"locked_door_puzzle"`).
  - `description`: A hint or clue about the puzzle that could be used for a hint system or just documentation. (For example, “The oak door in the study is locked tight.”)
  - `obstacle`: A short description of what the obstacle is, often the message the player sees initially (e.g., “The heavy oak door is locked.”).
  - `solution`: An object detailing how to solve it:

    - `verb`: The action needed (e.g., `"unlock"` or `"use"`).
    - `item`: The `id` of the required item (e.g., `"rusty_key"`).
    - `target`: (Optional) the `id` of the object or entity the item must be used on (e.g., `"oak_door"`). If omitted, using the item anywhere suffices, but typically we specify the target for clarity.

  - `reward_text`: The text to display when the puzzle is solved (often a narration of what happens, e.g., “The key turns in the rusty lock with a loud _click_, and the door creaks open.”).
  - `unlocks`: An action or effect that happens upon solving. This is usually a shorthand for the script to execute, such as enabling an exit or revealing a new item. For example, `{"type": "ENABLE_EXIT", "roomId": "study", "exit": "north"}` might open up a path, or `{"type": "REVEAL_ITEM", "item": "treasure_map"}` to place a new item in the room.

  Puzzles help the engine (and the player) by formalizing the win conditions. They tie together items and objects. The engine can use this to ensure the game is winnable (e.g., every puzzle’s required item is obtainable somewhere, and every puzzle’s `unlocks` leads to progress). It’s analogous to Sierra’s puzzle dependency charts, but here explicit in data.

- **Objects:** (Implicit in the format) We treat interactive scenery objects and characters as **objects** with their own properties and event scripts. Although the initial prompt structure in our LLM Protocol didn’t explicitly list an “objects” section, we infer it from the rooms and puzzles:

  - Many objects are essentially the obstacles or set pieces for puzzles (e.g., the locked door, a control panel, an NPC guard).
  - The JSON can include an `objects` array, each with:

    - `id`: unique id (e.g., `"oak_door"` or `"control_panel"`).
    - `name`: display name (“heavy oak door”, “dusty control panel”).
    - `description`: text when looking at it (if not in room description).
    - `events`: an object mapping event triggers to outcomes. These are the _scripts_ for that object, fully data-driven. For example:

      - `onLook`: { `responseText`: "...", possibly other actions }
      - `onTalk`: for NPCs, etc.
      - `onUse` or custom events like `onPush`, `onOpen`, `onUnlock` etc., which correspond to verbs.
      - Within each event, we can have:

        - `condition`: (optional) a boolean expression involving flags or state that must be true for the event to proceed.
        - `responseText`: the text to print when this event happens (narration or dialogue).
        - `actions`: a list of game actions to perform (these are similar to the puzzle `unlocks` but can be more varied). Actions might include state changes like `SET_FLAG`, `GIVE_ITEM`, `PLAY_SOUND`, `SHOW_MESSAGE`, `MOVE_VIEW` (to animate a character), etc. Each action is an object with a `type` and parameters.
        - Possibly alternative or fallback events (like `onUse_fallback` if condition isn’t met as shown in the control panel example).

  These object events allow the LLM to script specific behaviors for unique scenarios, ensuring key interactions are explicitly handled. In classic Sierra terms, this is our replacement for the SCI script code that a developer would write – except here it’s data that our EventManager interprets. For example, the **control panel** in the design example had an `onPush` event that only worked if power was on, otherwise an `onPush_fallback` with a different message. All of that is contained in the JSON for that object, and EventManager will handle it.

- **Views (Animated Sprites):** The JSON can also include a `views` section or incorporate view definitions under objects or characters:

  - Each view may have:

    - `id`: identifier (e.g., `"guard_view"`).
    - A set of animation loops, each a list of frames (cels) with durations, e.g., `"walk": [ {cel: {...}, duration:200}, {...} ]`, `"idle": [ ... ]`.
    - Optionally, each cel might be defined abstractly (we might not expect the LLM to output pixel data, but perhaps references to simple shapes or an index to a small sprite sheet of generic figures).
    - We might allow the LLM to describe a cel as an arrangement of colors (for example, a simple way: a matrix of 0/1 for two-color shapes, though this may be too granular). More realistically, the LLM might just select from a few predefined sprite styles (like “guard”, “dragon”, “hero”) and the engine has some templates.
    - For now, since generating pixel art via LLM is beyond current capabilities, we use placeholders or simple shapes to represent characters. For instance, the LLM could specify that a character uses a certain color and approximate size, and we draw a simple figure. Future iterations might integrate an image model to generate character sprites.

  The key is that each animated entity in the game (player, NPC, creatures, moving objects) has a view definition. The engine will load these, possibly generating the actual Image or canvas frames required from the description. The ViewManager uses these for animations.

- **Sound Resources:** Similar to views, we have sound descriptors:

  - Could be a list of sound effects or musical pieces with IDs. For instance, an entry might be `{ "id": "hologram_activates", "description": "a rising synth hum with a sparkling finish" }`. The engine might feed that description into a sound generator or pick a sound sample.
  - Music themes per room are already specified in rooms under `sound.music_theme`. We might collate them in a sound list if needed or just handle from room data.
  - Since generating actual audio waveforms is complex, we rely on procedural generation (via Tone.js) or choosing from a small library of retro-sounding effects by matching the description. For example, if the description contains "click", we play a click sound.
  - The format ensures each sound is associated with an event or location, keeping it manageable.

All of these sections tie together via IDs (for example, a puzzle references item and object IDs, a room references object IDs present, an object’s event might reference a sound ID to play or a view ID to reveal). The engine must ensure internal consistency – e.g., every ID used is defined somewhere. The LLM prompt explicitly asks it to keep references consistent. If any references are broken (say an exit points to a room ID that isn’t defined), the AIManager or a validation step will catch it and can ask the LLM for a correction or adjust accordingly.

**Example JSON Snippet:** _(An illustrative excerpt combining several elements.)_

```json
{
  "plot": {
    "title": "Mystery of the Haunted Lighthouse",
    "backstory": "A fierce storm strands you on an island with an abandoned lighthouse rumored to be haunted.",
    "goal": "Reignite the lighthouse beacon to signal for rescue."
  },
  "rooms": [
    {
      "id": "beach",
      "name": "Desolate Beach",
      "description": "Waves crash on a desolate beach. An old lighthouse stands atop a rocky cliff to the north.",
      "exits": { "north": "cliff_path" },
      "items": [ "driftwood" ],
      "objects": [ "rowboat" ],
      "sound": {
        "music_theme": "A somber, slow synth melody plays over the sound of waves.",
        "ambience": "The constant rolling of surf and an occasional distant gull."
      },
      "graphics": {
        "backgroundColor": "#0000AA",
        "primitives": [
          { "shape": "rect", "color": "#5555FF", "dims": [0, 120, 320, 80], "label": "ocean" },
          { "shape": "dithered_gradient", "colors": ["#5555FF", "#000000"], "dims": [0, 0, 320, 120], "label": "night_sky" },
          { "shape": "polygon", "color": "#AAAAAA", "points": [[0,200],[50,120],[80,120],[30,200]], "label": "rocks" },
          { "shape": "rect", "color": "#AAAAAA", "dims": [200, 130, 10, 70], "label": "lighthouse_tower" },
          { "shape": "triangle", "color": "#AAAAAA", "points": [[195,130],[215,130],[205,110]], "label": "lighthouse_top" },
          { "shape": "star", "color": "#FFFFFF", "points": [ [50, 50], [70, 30], [90, 55] ], "label": "stars" }
        ]
      }
    },
    ...
  ],
  "items": [
    {
      "id": "driftwood",
      "name": "a piece of driftwood",
      "description": "A water-worn piece of wood that washed up on the shore."
    },
    {
      "id": "rusty_key",
      "name": "a rusty key",
      "description": "An old key, red with rust. Perhaps it opens some ancient lock."
    }
    ...
  ],
  "objects": [
    {
      "id": "rowboat",
      "name": "a wrecked rowboat",
      "description": "The remains of a rowboat, smashed against the rocks.",
      "events": {
        "onLook": {
          "responseText": "The boat is beyond repair, but there might be something useful inside."
        },
        "onSearch": {
          "responseText": "You find a small brass key amid the debris!",
          "actions": [
            { "type": "REVEAL_ITEM", "itemId": "rusty_key" },
            { "type": "PLAY_SOUND", "soundId": "found_item_chime" }
          ]
        }
      }
    },
    {
      "id": "lighthouse_door",
      "name": "heavy wooden door",
      "description": "A heavy wooden door, swollen from moisture, barring entry to the lighthouse.",
      "events": {
        "onOpen": {
          "condition": "flags.door_unlocked == true",
          "responseText": "With a groan, the heavy door swings open.",
          "actions": [
            { "type": "ENABLE_EXIT", "roomId": "lighthouse_interior", "exit": "south" },
            { "type": "SET_FLAG", "name": "door_open", "value": true }
          ]
        },
        "onOpen_fallback": {
          "responseText": "You push with all your might, but the door is firmly locked."
        },
        "onUnlock": {
          "condition": "player.hasItem('rusty_key')",
          "responseText": "The rusty key turns in the lock, and you hear a satisfying *click*.",
          "actions": [
            { "type": "SET_FLAG", "name": "door_unlocked", "value": true },
            { "type": "SET_OBJECT_DESCRIPTION", "objectId": "lighthouse_door",
              "description": "The heavy door stands slightly ajar now." }
          ]
        },
        "onUnlock_fallback": {
          "responseText": "It’s locked. If only you had a key..."
        }
      }
    }
    ...
  ],
  "puzzles": [
    {
      "id": "open_lighthouse",
      "obstacle": "The lighthouse door is locked tight.",
      "solution": { "verb": "unlock", "item": "rusty_key", "target": "lighthouse_door" },
      "reward_text": "The door is unlocked. You can go inside the lighthouse now.",
      "unlocks": { "type": "ENABLE_EXIT", "roomId": "lighthouse_interior", "exit": "south" }
    }
    ...
  ]
}
```

In this example, you can see how items, puzzles, and objects interrelate (the puzzle “open_lighthouse” references the key and door; the door object has an `onUnlock` script that is triggered by using the key; the rowboat has an `onSearch` that gives the key to the player). The AI is expected to produce such a structure, and the engine will enforce it logically. Notably, the **16-color palette** is used in graphics (e.g., `#5555FF` bright blue, `#000000` black, etc.), and dithering is specified for the night sky gradient.

Our resource system is highly **data-driven**. Adding a new room or item in the JSON is enough for the engine to incorporate it – no code changes needed. This means the LLM has great freedom to craft the world, and the engine just needs to follow along interpreting the data. It’s imperative that the data remains consistent and the engine robustly handles any missing pieces or unexpected values (for instance, if the LLM output slightly deviates, the engine/AIManager might correct or request a regeneration).

## Save/Load System

The save/load system is designed for **perfect game state preservation**, crucial for an AI-generated game that cannot be reproduced by other means. Saving essentially serializes the entire `GameState` (which includes the generated content and the player’s progress) into a single file, typically in JSON format. Loading reverses this, restoring the game exactly.

Key points of the design:

- **Complete State Capture:** When the player saves, we capture _both_ the static content and the dynamic state:

  - The original AI-generated JSON (the “resource package”) is saved in its entirety. This ensures that even if the LLM service or prompts change later, the saved game contains everything needed (plot, rooms, descriptions, etc.). It’s like storing the game’s code and assets.
  - The dynamic state includes the current room the player is in, the inventory status (which items have been collected, which remain), all game flags and variables (puzzle solved flags, door opened flags, etc.), the exact state of each object (e.g., for each object: whether it’s been moved or used, its current description if altered, whether NPCs are present or gone), and the state of each animated view (which frame it was on, its coordinates, and whether it was mid-motion). We also include any pending events in the scheduler (timers that haven’t fired yet).
  - If the game uses a score, the current score is saved as well. If there’s a game time or move counter, that too can be saved.

- **Serialization Format:** We use JSON for the save file for readability and ease of debugging. The structure might look like:

  ```json
  {
    "version": 1,
    "resources": { ... entire generated game JSON ... },
    "state": {
       "currentRoom": "lighthouse_interior",
       "inventory": ["driftwood", "rusty_key"],
       "flags": { "door_unlocked": true, "door_open": true, "lit_beacon": false },
       "objects": {
         "lighthouse_door": { "description": "The heavy door stands slightly ajar now." }
       },
       "views": {
         "player": { "room": "lighthouse_interior", "x": 100, "y": 150, "loop": "idle", "frame": 0 },
         "ghost_npc": { "room": "lighthouse_interior", "x": 80, "y": 120, "loop": "idle", "frame": 2 }
       },
       "timers": [
         { "event": "ghostAppears", "timeRemaining": 5000 }
       ],
       "score": 50,
       "moves": 120
    }
  }
  ```

  This is an example, but it shows how we embed the resources and the state. The **version** field helps with future compatibility (if we change format, we can detect an old version and migrate it).

- **Save Process:** When the user triggers Save (via menu or command), the engine pauses the game and gathers the data:

  - We already have the original JSON (stored at game start). We attach that.
  - We traverse GameState to collect dynamic changes. We don’t need to store things that remain identical to the original JSON (to save space), but for simplicity we might just include everything; it’s easier and given that worlds are not huge, it’s fine if there’s duplication. Alternatively, we can store diffs like “which items removed from which rooms, which flags set, etc.”
  - The assembled JSON (with resources and state) is then offered to the user for download (e.g., as `somnium_save_1234.json`). This uses the HTML5 file APIs to let them save locally. The file is typically a few hundred kilobytes at most, since even text for a whole game is not large by modern standards (and could compress well if needed).
  - We ensure the file name or internal content includes the game title or seed, perhaps timestamp, for easier identification by the player.

- **Load Process:** On load, the chosen save file (the JSON) is read:

  - The engine checks the `version`. If it’s higher than what the engine knows, it might warn or attempt partial load. If lower, it may upgrade fields if needed. In the initial implementation, version 1 is assumed.
  - The engine replaces any current game in memory with the loaded one. This involves:

    - Taking the `resources` part and reinitializing GameState with it (rooms, items, etc.). Essentially, we load the game content exactly as originally generated.
    - Then apply the `state` diffs: set the current room, inventory, flags, object descriptions or removals (if an object is supposed to be removed from a room, we check inventory or a “removed” flag). We also recreate any dynamic objects that were created or destroyed.
    - Restore view states: place the player and NPCs at their saved coordinates and animation frame. If an animation was mid-play, we might just reset to the nearest frame or continue from that frame (though any continuous movement will likely restart).
    - Reschedule timers that were saved (adjusting them so that if a timer had 5 seconds remaining when saved, we give it that when resumed).
    - Restore the score, move count, etc.

  - After loading, the scene is redrawn and the game resumes exactly where left off. For example, if you saved in the middle of a ghost appearing event, upon load the ghost will still appear after 5 seconds as planned.

- **Integrity Checks:** After loading, the engine can run a quick consistency check (for debugging): ensure that all item references, exit links, etc., still make sense (they should, since it’s the same content). If any mismatch, it means the save file was tampered or corrupted, and the engine can alert the user or try to correct (e.g., if a required item is missing, perhaps re-add it).

- **Security Considerations:** Since save files are JSON, users might edit them (for fun or cheating). Our engine should handle unexpected values gracefully. For instance, if someone sets a flag in the save that wasn’t originally there, it might just be ignored. Or if they add an item to inventory that wasn’t obtained, it’s essentially a cheat but should not crash the game. We won’t heavily encrypt or lock saves – part of the fun of retro games is sometimes messing with save files – but we might include a simple checksum to detect changes and log it (without preventing loading). There’s no server-side risk since all is client, but we must ensure a malicious save file can’t break the engine (we’ll sanitize strings to avoid any script injection, etc., though running in a browser already has isolation).

- **Comparison to Sierra Saves:** Sierra’s SCI saves were binary blobs capturing the interpreter state (heap, stack, etc.). Ours is more transparent by design. But the philosophy is the same: a save file is essentially a memory dump of the game state. We explicitly include the content because unlike a shipped game, the content isn’t known by the engine otherwise. This is a unique challenge for AI games – hence our solution of bundling content with state.

- **Autosave:** We might implement autosave on major events or room changes, saving to browser localStorage. This would guard against browser crashes or accidental refresh. However, due to size, localStorage might only hold one autosave at a time. The user can also manually save as needed.

- **Restoring Experience:** When a game is restored, even the random elements should continue as before. For example, if the music track had a procedural element, we might store the random seed used to generate it so that after loading, the music doesn’t suddenly change. Similarly, if any randomness was in puzzles (though ideally puzzles are deterministic in one world), those outcomes are stored. The goal is the player shouldn’t be able to distinguish a loaded game from having never left the session.

In sum, the Save/Load system **freezes the dream** – capturing an AI-created adventure at a point in time and allowing it to be revisited or shared. Players could potentially exchange save files to share particularly interesting worlds with friends (though note: playing someone else’s save is like jumping into their story mid-progress, but one could start from beginning if they saved right after generation). The save files also serve as a record of the AI’s creation, which could be useful for feedback or debugging (we could inspect the JSON if something weird happened).
